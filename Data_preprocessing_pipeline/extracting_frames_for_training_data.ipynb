{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook makes two tasks:\n",
    "#### 1)splits videos into frames and saves the frames into newly created directory. For each video a separate directory is created.\n",
    "#### 2) Using previosely collected numerical values of the Avg.Wind and WingGust for the given date and time, we extrapolate the values corresponding to the video-file that just was split. Then the new csv file is created that contains a table of the following columns *name of the video*, *Avg.Wind*, *Wind Gusts*. This file will be used later to get labels for training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The working directories where are our video and csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir='../Data_samples/train data/'#path to train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating lists of names of video and csv files in these directiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all videofiles pathes inside of the working dir\n",
    "video_names = [root+'/'+file for root, _, files in os.walk(working_dir) for file in files if file.endswith('flv')]\n",
    "\n",
    "#list of all csv files pathes inside of workin dir\n",
    "csv_names   = [root+'/'+file for root, _, files in os.walk(working_dir) for file in files if file.endswith('csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking if everything is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-34.flv',\n",
       "  '../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-39.flv',\n",
       "  '../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-44.flv',\n",
       "  '../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-49.flv',\n",
       "  '../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-55.flv',\n",
       "  '../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-34.flv',\n",
       "  '../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-39.flv',\n",
       "  '../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-44.flv',\n",
       "  '../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-49.flv',\n",
       "  '../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-55.flv'],\n",
       " ['../Data_samples/train data//2018-05-01.csv',\n",
       "  '../Data_samples/train data//2018-05-02.csv',\n",
       "  '../Data_samples/train data//2018-05-03.csv',\n",
       "  '../Data_samples/train data//2018-05-04.csv',\n",
       "  '../Data_samples/train data//2018-05-05.csv',\n",
       "  '../Data_samples/train data//2018-05-06.csv',\n",
       "  '../Data_samples/train data//2018-05-07.csv',\n",
       "  '../Data_samples/train data//2018-05-08.csv',\n",
       "  '../Data_samples/train data//2018-05-10.csv',\n",
       "  '../Data_samples/train data//2018-05-12.csv',\n",
       "  '../Data_samples/train data//2018-05-24.csv',\n",
       "  '../Data_samples/train data//2018-05-25.csv',\n",
       "  '../Data_samples/train data//2018-05-26.csv',\n",
       "  '../Data_samples/train data//2018-05-27.csv',\n",
       "  '../Data_samples/train data//2018-05-28.csv',\n",
       "  '../Data_samples/train data//2018-05-29.csv',\n",
       "  '../Data_samples/train data//2018-05-30.csv',\n",
       "  '../Data_samples/train data//2018-05-31.csv',\n",
       "  '../Data_samples/train data//2018-07-07.csv',\n",
       "  '../Data_samples/train data//2018-07-08.csv',\n",
       "  '../Data_samples/train data//2018-07-09.csv',\n",
       "  '../Data_samples/train data//2018-07-10.csv',\n",
       "  '../Data_samples/train data//2018-07-11.csv',\n",
       "  '../Data_samples/train data//2018-07-14.csv',\n",
       "  '../Data_samples/train data//2018-07-15.csv',\n",
       "  '../Data_samples/train data/frames/wind_data_tg.csv'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_names, csv_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that splits video from *pathIn* into frames and saves them to *pathOut*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(pathIn, pathOut):\n",
    "    count = 0\n",
    "    vidcap = cv2.VideoCapture(pathIn)\n",
    "    success = True\n",
    "    while success and count<10:#second condition should be removed to extract all the frames\n",
    "        success,image = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        cv2.imwrite( pathOut + \"/fr-%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that converts filenames of the video into datatime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vn_to_time(vn):\n",
    "    return datetime.datetime.strptime(vn.split('/')[-1].split('.')[0], '%Y-%m-%d-%H-%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creation of one general DataFrame of numerical values from csv files for different dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_data=pd.DataFrame()\n",
    "for path in csv_names: \n",
    "    if path == '../Data_samples/train data/frames/wind_data_tg.csv':\n",
    "        continue\n",
    "    tabel=pd.read_csv(path,parse_dates=False).reset_index(drop=True)\n",
    "    wind_data=pd.concat([wind_data,tabel]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Avg. wind</th>\n",
       "      <th>wind gusts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2018-7-15-10-35</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>2018-7-15-10-40</td>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>2018-7-15-10-45</td>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>2018-7-15-10-50</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>2018-7-15-10-55</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  Avg. wind  wind gusts\n",
       "2879  2018-7-15-10-35         10        13.0\n",
       "2880  2018-7-15-10-40          9        13.0\n",
       "2881  2018-7-15-10-45          9        13.0\n",
       "2882  2018-7-15-10-50          8        12.0\n",
       "2883  2018-7-15-10-55         10        13.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function that produces the numerical values for given video. It finds two closest in time data points and makes interpolation. It also takes care of some edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_for_video(vn,wind_data):\n",
    "    vid_time=vn_to_time(vn)\n",
    "    #wd=wind_data.copy()\n",
    "    wind_data[\"time_diff\"]=wind_data['date'].apply(lambda x: \n",
    "                                                   (datetime.datetime.strptime(x,'%Y-%m-%d-%H-%M')-vid_time).total_seconds())\n",
    "    wind_data['time_dif_abs']=wind_data['time_diff'].apply(abs)\n",
    "    wd=wind_data.sort_values(['time_dif_abs']).head(2).reset_index(drop=True)\n",
    "    \n",
    "    if wd.empty:\n",
    "        return None\n",
    "    if wd['time_dif_abs'].min()>500:\n",
    "        return None\n",
    "    elif wd['time_dif_abs'].max()>1000:\n",
    "        awind=wd['Avg. wind'].loc[wd['time_dif_abs'].idxmin()]\n",
    "        gwind=wd['wind gusts'].loc[wd['time_dif_abs'].idxmin()]\n",
    "    \n",
    "    dt = wd['time_diff'].loc[1]-wd['time_diff'].loc[0]\n",
    "    if abs(dt)<1:\n",
    "        awind=(wd['Avg. wind'].loc[0]+wd['Avg. wind'].loc[1])/2\n",
    "        gwind=(wd['wind gusts'].loc[0]+wd['wind gusts'].loc[1])/2\n",
    "    else:\n",
    "        awind=(wd['Avg. wind'].loc[0]*wd['time_diff'].loc[1] - wd['Avg. wind'].loc[1]*wd['time_diff'].loc[0])/dt\n",
    "        gwind=(wd['wind gusts'].loc[0]*wd['time_diff'].loc[1] - wd['wind gusts'].loc[1]*wd['time_diff'].loc[0])/dt\n",
    "    return [awind,gwind]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the loop through all the videos, finding the numerical values for each given video. If numerical values are available, split video into frames and save the frames into directory. The corresponding tabel of numerical values is then saved into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-34.flv [14.2, 18.2] 0\n",
      "../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-39.flv [14.2, 17.8] 1\n",
      "../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-44.flv [14.8, 19.0] 2\n",
      "../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-49.flv [13.4, 19.0] 3\n",
      "../Data_samples/train data/ion-club-valdevaqueros/2018-07-11-18-55.flv [13.4, 18.4] 4\n",
      "../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-34.flv [14.2, 18.2] 5\n",
      "../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-39.flv [14.2, 17.8] 6\n",
      "../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-44.flv [14.8, 19.0] 7\n",
      "../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-49.flv [13.4, 19.0] 8\n",
      "../Data_samples/train data/valdevaqueros-tangana/2018-07-11-18-55.flv [13.4, 18.4] 9\n"
     ]
    }
   ],
   "source": [
    "frame_dir='../Data_samples/train data/frames/'\n",
    "try:\n",
    "    os.mkdir(frame_dir)#create dir if doesn't exist\n",
    "except FileExistsError:\n",
    "    pass\n",
    "wind_dict={}\n",
    "for i,vn in enumerate(video_names): #looping through all the video names\n",
    "    if 'tangana' in vn:\n",
    "        prefix='tg'\n",
    "    elif 'ion' in vn:\n",
    "        prefix='ion'\n",
    "    video_dir='video_{}{}'.format(prefix,i)\n",
    "    \n",
    "    pathout=frame_dir+video_dir+'/' #path to store the frames of a given video\n",
    "    \n",
    "    try:\n",
    "        winds=wind_for_video(vn,wind_data)#function that finds corresponding wind strength for the given video and writes it into same dir\n",
    "        if winds:\n",
    "            wind_dict[video_dir]=winds #create dict for wind strengths, the key id the video_dir\n",
    "            try:\n",
    "                os.mkdir(pathout)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            extract_images(vn,pathout) #function to split video and write the frames to the pathout dir\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(vn,wind_dict[video_dir],i)\n",
    "    except:\n",
    "        pass\n",
    "labels_df= pd.DataFrame.from_dict(wind_dict,orient='index')\n",
    "labels_df.rename(columns={0: \"avg. wind\", 1: \"wind gust\"},inplace=True)\n",
    "labels_df.to_csv(path_or_buf=frame_dir+'wind_data_tg.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
