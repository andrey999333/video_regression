{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, I build and train a dynamic model based on the pretrained static one. All weights are taken in such a way, that at the beginning of the training the prediction of the dynamic model is the same as prediction of the static model. So the precision of the static model is a base line for the dynamic one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import keras as keras\n",
    "from keras.layers import DepthwiseConv2D\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use tf.data API tensorflow session should be defined explicidly to run initializer of the data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First the generator is created to feed data from tfrecords files into the model during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This cell contains parsing function to decode serialized samples read from tfrecords files. It returns tuple of tf.tensors of 1) image in format (width,height,color_chanel), 2)label - array of two numbers and 3) the weights to be used in loss function to take into account unbalanced dataset. They are stored in to last two columns of the feature 'train/label' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto,seq_num):\n",
    "    \n",
    "    feature = {'train/seq': tf.VarLenFeature(tf.string),\n",
    "               'train/seq_len': tf.FixedLenFeature((1,),tf.int64),\n",
    "               'train/labels_weights': tf.FixedLenFeature((4,), tf.float32)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features=feature)\n",
    "    \n",
    "    #random_offset defines the first frame in a sample sequence \n",
    "    random_offset = tf.random_uniform(\n",
    "        shape=(), minval=0,\n",
    "        maxval= parsed_features[\"train/seq_len\"][0] - seq_num, dtype=tf.int64)\n",
    "    \n",
    "    #offset defines the sequence itself from the first to seq_num frame    \n",
    "    offsets = tf.range(random_offset,random_offset + seq_num,dtype=tf.int64)\n",
    "\n",
    "    #get sequence of frames and decode jpg into first uint8 and then normalize by 1/255. and convert to float32 type\n",
    "    seq = tf.map_fn(lambda i: tf.cast(tf.image.decode_jpeg(parsed_features['train/seq'].values[i])[:448,:704,:],tf.int64)\n",
    "                    ,offsets)\n",
    "    \n",
    "    seq = tf.cast(seq,tf.float32)/255.\n",
    "    \n",
    "    #get label for a sequence of frame (labals are all the same for the whole video)\n",
    "    labels_weights = parsed_features['train/labels_weights']\n",
    "    labels = labels_weights[0:2]\n",
    "    weights = labels_weights[2:]\n",
    "    \n",
    "    \n",
    "    return seq, labels,weights #, shapeseq_len, , name\n",
    "\n",
    "#a wrapper function to pass seq_num parameter into parser\n",
    "def _parse_function_param(seq_num):\n",
    "    def parse(example_proto):\n",
    "        return _parse_function(example_proto,seq_num)\n",
    "    return parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the batch size and the number of frames in a time serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_num = 4 # the number of frames shold be less than 16\n",
    "batch_size=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the list of tfrecords files to build the dataset from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = '../Data_samples/train data/tfrecords_seq/'#the directory with data in tfrecord format\n",
    "filenames = [working_directory+file for file in os.listdir(working_directory) if file.endswith('tfrecords')] #list of the filenames with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Important! To check if the list of the tfrecords files is good. The problem is if the list is empty, or the pathes are not readable for some reason, tf.data API does not produce an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data_samples/train data/tfrecords_seq/train0.tfrecords']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function_param(seq_num))\n",
    "dataset = dataset.repeat(1000)\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we have an iterator that produces a sample of frame sequence and corresponding labels. But we need an iterator that produces features after passing each frame through the convolutional base + attention. For that we next build a TimeDistributed feature extractor. The output of this Feature extractor can be directly fed into any kind dynamic layer such as time convolution of RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unfortunately the downloaded model from the h5 file doesnot work with TimeDistributed wrapper. To solve this problem the new identical static model is created and then the weights are taken from the pretrained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ttnnn\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:310: UserWarning: MobileNet shape is undefined. Weights for input shape(224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "#this is convolutional base\n",
    "conv_base=MobileNetV2(include_top=False)#,input_tensor=next_element[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=Input((None,None,None))\n",
    "x = inp\n",
    "\n",
    "x=conv_base(x)\n",
    "\n",
    "# next 5 layers are attention mechanism\n",
    "\n",
    "weights=Conv2D(1,(3,3),activation='sigmoid',padding='SAME',kernel_initializer=keras.initializers.Zeros(),\n",
    "                                               bias_initializer=keras.initializers.Ones())(x)\n",
    "\n",
    "#next two lines make the weights sum up to 1: weights->weights/sum(weights)\n",
    "norm = Lambda(lambda t: 1/K.sum(t,axis=[1,2]))(weights)\n",
    "\n",
    "weights = merge.multiply([norm,weights])\n",
    "\n",
    "#next two lines calculate weighted average\n",
    "x = merge.multiply([x,weights])\n",
    "\n",
    "x = Lambda(lambda t: K.sum(t,axis=[1,2]))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[inp],outputs=[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download the pretrained static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobinet1=load_model('../Static_models/mobile_mini_top_attention_3.h5',custom_objects={'relu6':ReLU(6.),'tf':tf},compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Redefining loaded model to output prediction values instead of the loss. In this case we don't need to feed true values and loss_weights for the loss function into the model. Defined in this way the architecture will be identical with the model build above and the trained weights can be assined (unfurtunately loaded model does not work with TimeDistributed wrapper, because of the bug)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobinet2=Model(inputs=[mobinet1.layers[0].input],outputs=[mobinet1.layers[6].output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(mobinet2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, None, None, N 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Model)    (None, None, None, 1 2257984     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 11521       mobilenetv2_1.00_224[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, None, None, 1 0           lambda_3[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, None, None, 1 0           mobilenetv2_1.00_224[1][0]       \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1280)         0           multiply_4[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,269,505\n",
      "Trainable params: 2,235,393\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next step is to wrapp the model in TimeDistributed wrapper, so it can take the sequence of frames simultaneously. At the moment we use stationary model without the top layers (conv_base + attention) to extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_time=TimeDistributed(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=Input((None,None,None,None))\n",
    "\n",
    "x=inp\n",
    "x=mob_time(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_mob=Model(inputs=[inp], outputs=[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a generator that produces sequence of features from the sequence of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "def batch_generator(dataset):\n",
    "    sess.run(iterator.initializer)\n",
    "    while True:\n",
    "        inputs, labels, weights = sess.run(next_element)\n",
    "        features=time_mob.predict_on_batch(inputs)\n",
    "        yield ([features, labels, weights],np.zeros((batch_size,))) # np.zeros are used as a dummy labels, since real labels\n",
    "                                                                        # will be fed alongside with the sample \n",
    "            \n",
    "gen=batch_generator(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[[9.24750030e-01, 8.42631832e-02, 8.35173484e-03, ...,\n",
       "           1.24393380e-03, 5.84371507e-01, 1.12202477e+00],\n",
       "          [7.71530271e-01, 1.88849926e-01, 1.69622526e-02, ...,\n",
       "           1.67293489e-04, 5.13913989e-01, 1.38477838e+00],\n",
       "          [6.21242702e-01, 1.37949333e-01, 1.78094618e-02, ...,\n",
       "           2.85055983e-04, 4.94020581e-01, 1.27388215e+00],\n",
       "          [5.50869703e-01, 1.48080498e-01, 3.70995104e-02, ...,\n",
       "           4.37595008e-05, 3.76173437e-01, 1.17835510e+00]],\n",
       "  \n",
       "         [[1.02637482e+00, 1.69418883e+00, 1.08623005e-01, ...,\n",
       "           1.36557028e-01, 4.97790635e-01, 8.70172977e-01],\n",
       "          [1.04836440e+00, 1.67417526e+00, 2.32100829e-01, ...,\n",
       "           1.31708965e-01, 2.62945414e-01, 8.26941609e-01],\n",
       "          [7.79519737e-01, 1.76763773e+00, 2.51860738e-01, ...,\n",
       "           1.50727287e-01, 1.83511093e-01, 4.90075111e-01],\n",
       "          [7.64925539e-01, 1.73200524e+00, 2.58311003e-01, ...,\n",
       "           2.37498417e-01, 9.03775021e-02, 5.37468433e-01]],\n",
       "  \n",
       "         [[9.71853912e-01, 1.15448797e+00, 5.35539448e-01, ...,\n",
       "           1.29755542e-01, 3.68908972e-01, 6.92701101e-01],\n",
       "          [7.82064497e-01, 8.32089365e-01, 4.74897742e-01, ...,\n",
       "           7.18136281e-02, 3.19121212e-01, 5.60064375e-01],\n",
       "          [1.00297189e+00, 1.13699007e+00, 5.43206453e-01, ...,\n",
       "           6.58519939e-02, 3.02198201e-01, 7.03360558e-01],\n",
       "          [1.04116881e+00, 1.23634005e+00, 4.90221530e-01, ...,\n",
       "           1.49236515e-01, 2.28682786e-01, 9.74968731e-01]]], dtype=float32),\n",
       "  array([[14.2, 17.8],\n",
       "         [13.4, 19. ],\n",
       "         [14.2, 18.2]], dtype=float32),\n",
       "  array([[0.8333333, 2.5      ],\n",
       "         [1.25     , 0.625    ],\n",
       "         [0.8333333, 0.625    ]], dtype=float32)],\n",
       " array([0., 0., 0.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now the final top layers are constructed to deal with dynamics. This final model contains two branches that are connected residually to produce the final prediction. One branch is essentially averaging of the static model predictions along the time axis. Another branch is either 1) 1D convolution along the time axis. In this case the initial values of the weights and biases are set to zero, thus the model starts with static prediction averaged over time 2) A layer of GRU cells 3) A layer of LSTM cells. The function that build the model accept 3 possible values for 'type_of_layer' parameter 'conv', 'GRU' and 'LSTM'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1=mobinet1.layers[7] # a final layer of static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_temp_model(type_top_layer='conv'):\n",
    "    inp0 = Input(shape=(seq_num,1280))# \n",
    "    inp1 = Input(shape=(2,))\n",
    "    inp2 = Input(shape=(2,))\n",
    "\n",
    "    x = inp0\n",
    "    labels = inp1\n",
    "    loss_weights = inp2\n",
    "\n",
    "    x = TimeDistributed(dense1)(x) #static prediction\n",
    "\n",
    "    avg = GlobalAveragePooling1D()(x) #averaging of the static prediction\n",
    "    \n",
    "    if type_top_layer=='conv':\n",
    "        x=Conv1D(2,3,kernel_initializer=keras.initializers.Zeros(), #time convolution branch\n",
    "                                                           bias_initializer=keras.initializers.Zeros())(x)\n",
    "        x=GlobalAveragePooling1D()(x) # averaging along time axis\n",
    "    \n",
    "    elif type_top_layer=='GRU':\n",
    "        x=GRU(2)(x)\n",
    "    \n",
    "    elif type_top_layer=='LSTM':\n",
    "        x=LSTM(2)(x)\n",
    "    \n",
    "    else:\n",
    "        raise NameError('Unknown type of model. Possible types are: \"conv\",\"GRU\" or \"LSTM\"')\n",
    "\n",
    "    prediction = Add()([avg,x]) # final prediction is a summ of two branches\n",
    "\n",
    "    # constructing the weighted loss\n",
    "    err = subtract([prediction,labels])\n",
    "    sqr_err = Lambda(K.square)(err)\n",
    "    weighted_sqr_err = multiply([sqr_err,loss_weights])\n",
    "    loss = Lambda(K.mean)(weighted_sqr_err)\n",
    "    \n",
    "    return Model(inputs=[inp0,inp1,inp2], outputs=[loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Build_temp_model(type_top_layer='conv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the model has been trained before, download pretraind one for further training. Uncomment the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_trained=load_model('mobile_dynamics1.h5',custom_objects={'relu6':ReLU(6.),'tf':tf},compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.set_weights(model_trained.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As usual dummy los function for compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_compile(y_true,y):\n",
    "      return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer=adam,loss=loss_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    model1.fit_generator(gen, epochs=1,steps_per_epoch=100)\n",
    "    model1.save(\"mobile_dynamics_{}.h5\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stop the virtual machine after training if on the cloud, to avoid paying for idle GPU time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sudo poweroff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
