{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook I train the full model combining convolutional base from MobiNetV2 and the top layers pretrained in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use tf.data API tensorflow session should be defined explicidly to run initializer of the data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This cell contains parsing function to decode serialized samples read from tfrecords files. It returns tuple of tf.tensors of 1) image in format (width,height,color_chanel), 2)label - array of two numbers and 3) the weights to be used in loss function to take into account unbalanced dataset. They are stored in to last two columns of the feature 'train/label' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    feature = {'train/image': tf.FixedLenFeature((), tf.string),\n",
    "               'train/label': tf.FixedLenFeature((4,), tf.float32)}\n",
    "    \n",
    "    parsed_features = tf.parse_single_example(example_proto, features=feature)\n",
    "    \n",
    "    image = tf.cast(tf.image.decode_jpeg(parsed_features['train/image']),dtype=tf.float32)/255.\n",
    "    image = image[:448,:704,:]#crop the images from different cameras to make them of the same size \n",
    "    \n",
    "    labels = parsed_features['train/label'][0:2]\n",
    "    weights  = parsed_features['train/label'][2:]\n",
    "    \n",
    "    return image, labels, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Difining Iterator to feed data into model as np.array. It is possible to feed tensorflow tensors directly into the model, but it apeared to be less convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['tfrecord/train{}.tfrecords'.format(i) for i in range(100)]\n",
    "batch_size=12\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.repeat(100)\n",
    "dataset = dataset.batch(batch_size)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "def batch_generator(dataset):\n",
    "    with K.get_session().as_default() as sess:\n",
    "        sess.run(iterator.initializer)\n",
    "        while True:\n",
    "            images, labels, weights = sess.run(next_element)\n",
    "            yield ([images, labels, weights],np.zeros((batch_size,)))# np.zeros are used as a dummy labels, since real labels\n",
    "                                                                     # will be fed alongside with the sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stat=load_model('mobile_mini_top_attention_3.h5',custom_objects={'relu6':ReLU(6.),'tf':tf},compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, None, None, N 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Model)    (None, None, None, 1 2257984     input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 11521       mobilenetv2_1.00_224[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, None, None, 1 0           lambda_9[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, None, None, 1 0           mobilenetv2_1.00_224[1][0]       \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1280)         0           multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            2562        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 2)            0           dense_3[0][0]                    \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2)            0           subtract_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 2)            0           lambda_11[0][0]                  \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              ()                   0           multiply_9[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,272,067\n",
      "Trainable params: 2,237,955\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_stat.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to use fit_generator method we need to define the custom dummy loss function. Since the model already produces loss as an output, all we need is to return the predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_compile(y_true,y):\n",
    "      return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining optimizer and compile model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=.0001)\n",
    "gen=batch_generator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stat.compile(optimizer=adam,loss=loss_compile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training of the model. The for-loop is used to return the decaying learning rate back to it's original value and by that create additional disturbance to avoid falling into local minimum and also saving the model every N iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    model_stat.fit_generator(gen,epochs=1,steps_per_epoch=100)\n",
    "    model_stat.save('model_stat_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the final trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stat.save('mobile_mini_top_attention_3.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
